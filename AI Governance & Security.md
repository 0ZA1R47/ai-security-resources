## Step# 1: Learn ML 
	- Supervised vs Unsupervised
	- Neural Networks and Deep learning
	- Reinforcement learning
	- Feature Engineering
	- Model Evaluation and validation

## Step #2:  Learn AI Biases 
	- Types of biases (sampling, measurement, algorithm biases, etc. )
	- Ethical implications of biased AI systems
	- Techniques for mitigating biases (e.g. re-sampling, re-weighting, and adversial learning)

## Step# 3: Learn about Specific AI Attacks 
	- Adversarial examples
	- Data poisoning
	- Model inversion and extraction
	- Membership inference attacks
![[Pasted image 20240525161028.png]]

## Step# 4: AI Governance 
	- Learn the fundamentals of AI 
	- Understand AI risks, how to identify and mitigate 
	- AI Governance frameworks and best practices
	- AI Risk assessment methodologies 
	- Compliance with relevant laws
	- Incident response and recovery plans for AI systems 
	- Standards, Frameworks, and regulations 
	- Frameworks
		- OWASP LLM AI Security & Governance Checklist
		- NIST AI RMF
		- MITRE ATLAS
		- EU AI Act
		- ISO 42001 AIMS 
		- ISO 22989 / 23053 / 23894
		- IEEE 3652.1-2020 / 2830-2021 / 2937-2022
		- US President's EO on the Safe, Secure, & Trustworthy Development & Use of A
	
## Step# 5: Security Controls 
	- MITRE ATALS Framework for AI threat modelling
	- Data Protection (e.g; encryption, access control, etc.)
	- Secure model training and deployment 
	- Robustness testing and validation 
	- Monitoring and auditng of AI systems 

# Resources
- EU AI Office https://digital-strategy.ec.europa.eu/en/policies/ai-office
- https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/wiki/Educational-Resources
- EU AI Act Navigator https://artificialintelligenceact.eu/developments/ 
- Robust Intelligence AI Safety & Security Taxonomy https://www.robustintelligence.com/ai-security-and-safety-taxonomy
- Robust Intelligence AI Security Reference Architectures https://www.robustintelligence.com/ai-security-reference-architectures
- Robust Intelligence  GenAI Risk Assessment case studie of Falcon LLM  https://www.robustintelligence.com/generative-ai-risk-assessment-falcon
- AI CTI Updates https://www.robustintelligence.com/company/blog?category=Threat+Intelligence
- OWASP® Foundation AI Exchange https://owaspai.org
- OWASP ML Security Top 10 https://mltop10.info
- OWASP Top 10 for LLM Applications https://genai.owasp.org
- OWASP LLM AI Cybersecurity and Governance Checklist https://lnkd.in/d6GjCPRu
- OWASP AI Security & Privacy Guide https://lnkd.in/dpqVt3zS
- NIST AI 100-1 (AI RMF 1.0) https://lnkd.in/dMFMBRf8
- NIST AI RMF Playbook https://lnkd.in/dEHJmwgD
- MITRE ATLAS™ https://lnkd.in/d2j9WG_T
- A Sensible Regulatory Framework for AI Security from MITRE https://lnkd.in/dwzttNsA
- ISO/IEC 42001:2023 AIMS https://lnkd.in/dzChTAeQ
- ISO/IEC CD 27090 Guidance for addressing security threats & failures in AI systems https://lnkd.in/d4hMBH4h
- ISO/IEC WD 27091.2 AI Privacy Protection https://lnkd.in/dk2Zmm2H
- AI & Cybersecurity Research from ENISA https://lnkd.in/d5TMUQJk
- Multilayer Framework for Good Cybersecurity Practices for AI from ENISA https://lnkd.in/dqXD2uK9
- Key Considerations for Developing Organizational Gen AI Policies by Ms. Mary Carmichael https://lnkd.in/dxtF3Xbu
- Gen AI for Organizational Use: Internal Policy Checklist from FPF https://lnkd.in/dhJUYBZp
- Auditing AI from ISACA https://lnkd.in/d9ZrmE3s
- The EU AI Act https://lnkd.in/d8faAThr
- EO 14110 on the Safe, Secure, and Trustworthy Development & Use of AI https://lnkd.in/duW8i-_P
- Joint Guidance on Deploying AI Systems Securely https://lnkd.in/deN9HrNU
- Engaging with AI https://lnkd.in/dx5JMMRg
- NCSC Guidelines for secure AI system development https://lnkd.in/diKUZYVZ
- Risks & Mitigation Strategies for Adversarial AI Threats: A DHS S&T Study https://lnkd.in/dCWSgssV
- GSA AI Guide for Government https://lnkd.in/dGaNkyHw
- The U.S. DoD CDAO Responsible AI Toolkit including Defense AI Guide on Risk (DAGR) https://lnkd.in/dAVy3c5H
- A Unified Framework of Five Principles for AI in Society, Harvard Data Science Review https://lnkd.in/daEYgbCG
- A Taxonomy of Trustworthiness for Artificial Intelligence: Connecting Properties of Trustworthiness with Risk Management & the AI Lifecycle by Ms. Jessica Newman from Center for Long-Term Cybersecurity (CLTC) https://lnkd.in/duJ-5m4F
- Ethics & governance of artificial intelligence for health from WHO https://lnkd.in/dJ27hjvP
- Strengthening & Democratizing the U.S. AI Innovation Ecosystem: An Implementation Plan for a National AI Research Resource https://lnkd.in/db6HhQ4v
- Stanford Institute for Human-Centered Artificial Intelligence (HAI) AI Bill of Rights https://lnkd.in/ddt34f8r
- Best practices for AI & Workplace Assessment Technologies from Future of Privacy Forum (FPF) https://lnkd.in/dZJBpxwr
- dlapiperdataprotection.com - repo of DP laws
- fairly.ai/blog/map-of-global-ai-regulations - 
- iapp.org - global ai legislation tracker
- Microsoft RAI Standards - Impact Assessment guide - RAI dashboard - GitHub Repo 
# GenAI Governance & Compliance
- The convergence of Ethics & Regulations needs to be considered for Responsible/Trustworthy AI
- The compliance consideration parameters 
	- Geographical Impact
	- Applicable types of regulations 
	- Type of activity & AI level of risk 
- Checklist:
	- Inventory the GenAI projects 
	- Pre analyze the potential risk for a given project 
	- Explore all applicable regulations 
	- Identify external and internal stake holders
	- Map the use case EU AI Act's level of risks
	- Analyze technology stack and providers
	- Explore and test responsible AI toolkits
	- Reflect on potential geo expansion 
	- Prepare Internal training activities for AI topics 
	- Keep iterating to evolve your GenAI compliance
- Effective Governance
	- Define use cases
	- Training data disclosure
	- Risk mitigation measures
	- Risks from training data and bad actors
	- Consequences and compliance 
- Evaluating AI systems 
	 - Bias identification and evaluation
	 - Compliance audit
	 - Ideal governance process
	 - model details
	 - Transparency and accountability 
- High Impact Sectors
	- Finance 
	- Healthcare 
- Ethics by design
	- Every component of the project must consider ethics at the beginning 
	- Get answers of below for embedding ethics by design
	- Meaning of being fair
	- Internals of algo
	- Trust
	- Auditors 
	- Privacy regulations
	- Good solution for the problem
	- Model performance & Bias
	- Ethics require a mindset shift and considering the implications, risks, & benefits on users, society, & env. 
	- Set up Ethics board (multilayered, cross cultural, and dept.)
- Risks & Mitigation 
	- Security
	- Ops
	- Ethics 
	- Bias
		- Training data quality check by diverse group to audit and validate who is missing?
		- Mitigate by oversampling or synthetic data 
	- Privacy 
		- Data Leakage 
		- Ask for user consent , Call out for new consent in case of changes, build ethical and secure by design systems
	- Risks manifest in various stages of model development lifecycle


## Security Issues 
- ![[Pasted image 20240708211204.png]]
- ![[Pasted image 20240708211450.png]]

## Robust Intelligence Podcast on Best Practices for GenAI RM
- Data Governance along with other Security & AI governance
- AI risk management along with diff lines of defenses (auditors, etc.)
- AI Risk database to identify vulnerable models and you can reference it for validation while deploying 
- AI Security would be a hot field in 3-5 years and companies would require 3rd Party help
- Pre production security - Model security & Health by controlling training data, etc. - shift left 
- Test as you build 
- CI/CD
## JD# 1- Cotviti-US

The **Information Security - AI Governance and Risk** will lead the development and implementation of governance frameworks for AI systems while overseeing risk management strategies related to information security. This role is pivotal in aligning AI technologies with organizational security policies, regulatory requirements, and ethical standards. The ideal candidate will work closely with cybersecurity teams, data scientists, and compliance officers to ensure secure and responsible AI deployment.

Responsibilities
 Develop, implement, and maintain governance frameworks for AI systems in alignment with security and regulatory requirements. 
 Establish AI governance policies that ensure ethical use, transparency, and compliance with internal and external standards. 
 Identify and assess risks associated with AI models, including adversarial threats, data leakage, and systemic vulnerabilities. 
 Develop risk management strategies that mitigate identified vulnerabilities and ensure robust AI system security. 
 Research, select, and implement appropriate tools to mitigate security risks. 
 Collaborate with cross-functional teams, including data science, cybersecurity, and legal/compliance, to implement AI security policies and ensure procedure development. 
 Work with data privacy officers to ensure AI systems adhere to privacy 
 Oversee periodic audits of AI systems to verify compliance with security and ethical standards. 
 Monitor adherence to global AI governance standards and ensure readiness for external certification. 
 Conduct training sessions to raise awareness about AI security, risk management, and ethical guidelines among relevant stakeholders. 
 Complete all responsibilities as outlined in the annual performance review and/or goal setting . 
 Complete all special projects and other duties as assigned. 
 Must be able to perform duties with or without reasonable accommodation. 

This job description is intended to describe the general nature and level of work being performed and is not to be construed as an exhaustive list of responsibilities, duties and skills required. This job description does not constitute an employment agreement and is subject to change as the needs of Cotiviti and requirements of the job change.

Qualifications

 Bachelor's degree in Computer Science, Cybersecurity, Data Science, or a related field. 
 Minimum of 8+ years of experience in information security, security audits and assessments, governance, and risk management. 
 Strong understanding of AI governance principles, risk assessment methodologies, and regulatory compliance, machine learning models, adversarial attacks. 
 Strong knowledge of AI technologies and governance principles and their inherent security risks. 
 Familiarity with machine learning models, adversarial attacks, and data privacy regulations
 Relevant certifications like CISSP, CISM, CRISC, or AI ethics/security credentials are a plus. 
 Excellent communication and leadership skills to work across diverse teams. 
 Excellent analytical skills to identify and address security vulnerabilities in AI systems. 

Mental Requirements

 Communicating with others to exchange information. 
 Problem-solving and thinking critically. 
 Works independently with little supervision. 
 Ability to lead projects with little guidance 
 Interpreting data. 
 Making timely decisions in the context of a workflow. 
 Maintaining focus. 
 Remembering and adhering to processes and protocols. 
 Assessing the accuracy, neatness and thoroughness of the work assigned. 
 Applying established protocols in a timely manner

## JD# 2
The AI Information Risk Analyst will be responsible for identifying, evaluating, and mitigating risks associated with the use of generative AI technologies in our organization. This role requires a blend of technical expertise, analytical skills, and strong ethical judgment to ensure that our AI initiatives are both effective and compliant with regulatory standards.

Roles & Responsibilities

Key Responsibilities

 Conduct comprehensive risk assessments of generative AI systems, identifying potential vulnerabilities and threats.
 Collaborate with cross-functional teams to design and implement robust AI security measures.
 Ensure compliance with relevant legal, regulatory, and industry standards related to AI and data privacy.
 Develop and maintain risk management frameworks and policies specific to AI applications.
 Perform regular audits and assessments to monitor the effectiveness of risk mitigation strategies.
 Provide expert guidance on AI ethics and responsible AI practices.
 Prepare detailed reports and presentations on risk assessment findings and recommendations for senior management.
 Stay updated with the latest advancements in AI, cybersecurity, and risk management practices.

Top 3 Must-Haves (Hard And/or Soft Skills)

 Understanding of AI/ML concepts, algorithms, and models.
 In-depth familiarity with cybersecurity principles and practices.
 Understanding of IT infrastructure, cloud platforms (AWS, Azure, Google Cloud), and their security protocols.

Top 3 Nice-To-Haves (Hard and/or Soft Skills)

Ability to think analytically and critically about potential risks.
Ability to work effectively with cross-functional teams, including data scientists, IT professionals, legal advisors, and business leaders.
Strong sense of ethics and responsibility regarding AI deployment and its societal impacts.
Education Requirements (Experience in Lieu of Degree): Any AI certifications
Certification Requirements (Any Preferences): CIAP (nice to have)
How many years of experience are you looking for 5-10 of risk experience, 2 years AI